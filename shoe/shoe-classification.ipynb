{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:5]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-06T14:59:24.039745Z","iopub.execute_input":"2022-12-06T14:59:24.040168Z","iopub.status.idle":"2022-12-06T14:59:28.283573Z","shell.execute_reply.started":"2022-12-06T14:59:24.040136Z","shell.execute_reply":"2022-12-06T14:59:28.282361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# organize the datasets url ","metadata":{}},{"cell_type":"code","source":"val_dir = '/kaggle/input/shoes-classification-dataset-13k-images/Shoes Dataset/Valid'\ntest_dir = '/kaggle/input/shoes-classification-dataset-13k-images/Shoes Dataset/Test'\ntrain_dir = '/kaggle/input/shoes-classification-dataset-13k-images/Shoes Dataset/Train'","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:59:28.286041Z","iopub.execute_input":"2022-12-06T14:59:28.286477Z","iopub.status.idle":"2022-12-06T14:59:28.292339Z","shell.execute_reply.started":"2022-12-06T14:59:28.286431Z","shell.execute_reply":"2022-12-06T14:59:28.291020Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# set up the dataset thourgh this two apis \n- ImageDataGenerator\n- flow_from_directory","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    )\nval_datagen = ImageDataGenerator(\n    rescale=1./255,\n)\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size = (180,180),\n    batch_size=32,\n)\nval_generator = train_datagen.flow_from_directory(\n    val_dir,\n    target_size = (180,180),\n    batch_size=32,\n    \n)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:59:28.293652Z","iopub.execute_input":"2022-12-06T14:59:28.293980Z","iopub.status.idle":"2022-12-06T14:59:28.736098Z","shell.execute_reply.started":"2022-12-06T14:59:28.293952Z","shell.execute_reply":"2022-12-06T14:59:28.734879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# classification target ","metadata":{}},{"cell_type":"code","source":"labels = ['Ballet Flat','Boat','Brogue','Clog','Sneaker']\nnum_classes = len(labels)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:59:28.737620Z","iopub.execute_input":"2022-12-06T14:59:28.738759Z","iopub.status.idle":"2022-12-06T14:59:28.744912Z","shell.execute_reply.started":"2022-12-06T14:59:28.738703Z","shell.execute_reply":"2022-12-06T14:59:28.743383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# build model ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg19 import VGG19\nmodel = VGG19(weights='imagenet',include_top=False)\n# from keras.layers.serialization import activation\nresult = model.output \nfrom tensorflow.keras.layers import Dense,GlobalAveragePooling2D\nresult = GlobalAveragePooling2D()(result)\nresult = Dense(512,activation='relu')(result)\npredictions = Dense(num_classes,activation='sigmoid')(result)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:59:28.747640Z","iopub.execute_input":"2022-12-06T14:59:28.748428Z","iopub.status.idle":"2022-12-06T14:59:29.375025Z","shell.execute_reply.started":"2022-12-06T14:59:28.748390Z","shell.execute_reply":"2022-12-06T14:59:29.373795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \nfrom tensorflow.keras.models import Model\nvgg_model = Model(inputs=model.input,outputs=predictions)\n\n\nvgg_model.compile(\n    loss='categorical_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n    metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:59:29.376498Z","iopub.execute_input":"2022-12-06T14:59:29.377591Z","iopub.status.idle":"2022-12-06T14:59:29.396237Z","shell.execute_reply.started":"2022-12-06T14:59:29.377549Z","shell.execute_reply":"2022-12-06T14:59:29.394883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf \n\ncallback =[ \n    tf.keras.callbacks.EarlyStopping(patience=3),\n    \n          ]\nwith tf.device(\"/device:GPU:0\"):\n    \n    history = resnet_model.fit_generator(\n        train_generator,\n        epochs=50,\n        shuffle=True,\n        verbose=1,\n        validation_data=val_generator,callbacks = callback)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T14:59:29.397754Z","iopub.execute_input":"2022-12-06T14:59:29.398168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# summarize history for accuracy\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['Pretrained'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['Pretrained'], loc='upper left')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history['accuracy'][-1]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}